training:
  learning_rate: 2e-5
  batch_size: 8
  max_epochs: 3
  accelerator: "auto"

lora:
  r: 8
  alpha: 16
  target_modules: ["q_proj", "v_proj"]
  dropout: 0.05
